{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append('../Models')\n",
    "from utils import PrimalDualSolver_l2, ProjectedGradientDescent_l2\n",
    "\n",
    "\n",
    "class SDL_simple:\n",
    "    \"\"\"\n",
    "    Supervised Dictionary Learning (SDL) Class.\n",
    "\n",
    "    Combines sparse coding with supervised learning by jointly learning:\n",
    "    - A dictionary `D` for sparse representation.\n",
    "    - A linear model `(theta, b)` for predicting labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iter=10,\n",
    "                 lamnda0=0.01,\n",
    "                 lambda1=0.1,\n",
    "                 lambda2=0.1,\n",
    "                 lr_D=0.01,\n",
    "                 lr_theta=0.01,\n",
    "                 lr_alpha=0.01,\n",
    "                 lambd=0.01):\n",
    "        self.n_iter = n_iter\n",
    "        self.lamnda0 = lamnda0\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lr_D = lr_D\n",
    "        self.lr_theta = lr_theta\n",
    "        self.lr_alpha = lr_alpha\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def objective(self, X, y, D, theta, b, alpha):\n",
    "        \"\"\"Computes the objective function value with separate terms.\"\"\"\n",
    "        total_loss_dict = 0\n",
    "        total_loss_class = 0\n",
    "        total_sparse_penalty = 0\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            xi, yi, ai = X[i], y[i], alpha[i]\n",
    "\n",
    "            # Compute each term\n",
    "            loss_dict = np.linalg.norm(xi - D @ ai)**2\n",
    "            loss_class = np.linalg.norm(yi - (theta @ ai + b))**2\n",
    "            sparse_penalty = self.lambda1 * np.linalg.norm(ai, 1)\n",
    "\n",
    "            # Accumulate terms\n",
    "            total_loss_dict += loss_dict\n",
    "            total_loss_class += loss_class\n",
    "            total_sparse_penalty += sparse_penalty\n",
    "\n",
    "        # Combine the terms\n",
    "        total_objective = total_loss_dict + total_loss_class + total_sparse_penalty\n",
    "        return total_objective\n",
    "\n",
    "    def loss_prediction(self, X, y, D, theta, b, alpha):\n",
    "        \"\"\"Computes the classification loss.\"\"\"\n",
    "        total_loss = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            xi, yi, ai = X[i], y[i], alpha[i]\n",
    "            loss = np.linalg.norm(yi - (theta @ ai + b))**2\n",
    "            total_loss += loss\n",
    "        return total_loss\n",
    "\n",
    "    def solve_alpha(self, X, y, D, theta, b):\n",
    "        \"\"\"Optimizes sparse codes `alpha` for fixed `D` and `theta`.\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        alpha = np.zeros((n_samples, n_features))\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x_i = X[i]\n",
    "            y_i = y[i]\n",
    "\n",
    "            solver = PrimalDualSolver_l2(\n",
    "                theta=theta, b=b, x_i=x_i, y_i=y_i, D=D,\n",
    "                lambda_0=self.lamnda0, lambda_1=self.lambda1,\n",
    "                lambd=self.lambd, mu=1.0\n",
    "            )\n",
    "            # Solve the problem\n",
    "            x0 = np.random.randn(n_features)  # Random initialization\n",
    "            alpha_opt, _ = solver.solve(x0)\n",
    "\n",
    "            alpha[i] = alpha_opt\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def solve_D_theta(self, alpha_opt, X, y, D_opt, theta_opt, b):\n",
    "        \"\"\"Updates `D` and `theta` given the optimal `alpha`.\"\"\"\n",
    "        pgd = ProjectedGradientDescent_l2(\n",
    "            D_init=D_opt, theta_init=theta_opt,\n",
    "            b=b, x=X, y=y, alphas=alpha_opt,\n",
    "            lambda_0=self.lamnda0,\n",
    "            lambda_1=self.lambda1, lambda_2=self.lambda2,\n",
    "            lr=self.lr_D, max_iter=self.n_iter\n",
    "        )\n",
    "        D_opt, theta_opt, b_opt, _ = pgd.optimize()\n",
    "        return D_opt, theta_opt, b_opt\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fits the model to the data.\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        self.n_components = n_features\n",
    "        D_opt = np.random.randn(n_features, self.n_components)\n",
    "        D_opt /= np.linalg.norm(D_opt, axis=0)\n",
    "        theta_opt = np.zeros(self.n_components)\n",
    "        b_opt = 0\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            alpha_opt = self.solve_alpha(X, y, D_opt, theta_opt, b_opt)\n",
    "            D_opt, theta_opt, b_opt = self.solve_D_theta(alpha_opt,\n",
    "                                                            X,\n",
    "                                                            y,\n",
    "                                                            D_opt,\n",
    "                                                            theta_opt,\n",
    "                                                            b_opt)\n",
    "            # Compute the loss\n",
    "            loss = self.objective(X, y, D_opt, theta_opt, b_opt, alpha_opt)\n",
    "            print(f\"Iteration {i+1}/{self.n_iter}, Loss: {loss}\")\n",
    "            print(f\"Iteration {i+1}/{self.n_iter}, Loss classification: {self.loss_prediction(X, y, D_opt, theta_opt, b_opt, alpha_opt)}\")\n",
    "\n",
    "            # Stop the model if the loss is NaN\n",
    "            if np.isnan(loss):\n",
    "                print(\"Loss is NaN. Stopping optimization.\")\n",
    "                break\n",
    "\n",
    "        self.alpha = alpha_opt\n",
    "        self.D = D_opt\n",
    "        self.theta = theta_opt\n",
    "        self.b = b_opt\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts labels for input data `X`.\"\"\"\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            x_i = X[i]\n",
    "            alpha, _, _, _ = np.linalg.lstsq(self.D, x_i, rcond=None)\n",
    "            prediction = self.theta @ alpha + self.b\n",
    "            predictions.append(prediction)\n",
    "        return np.sign(np.array(predictions))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Computes classification accuracy.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(np.round(y_pred) == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10, Loss: 25204.422782856516\n",
      "Iteration 1/10, Loss classification: 22103.430123526443\n",
      "Iteration 2/10, Loss: 3116.3615197649797\n",
      "Iteration 2/10, Loss classification: 0.36066456177186995\n",
      "Iteration 3/10, Loss: 3099.8651714636976\n",
      "Iteration 3/10, Loss classification: 0.3834475388819589\n",
      "Iteration 4/10, Loss: 3071.527807386007\n",
      "Iteration 4/10, Loss classification: 0.3402792126546438\n",
      "Iteration 5/10, Loss: 3064.8620173396885\n",
      "Iteration 5/10, Loss classification: 0.33225744263924245\n",
      "Iteration 6/10, Loss: 3071.5777221677904\n",
      "Iteration 6/10, Loss classification: 0.33315375791015167\n",
      "Iteration 7/10, Loss: 3057.732594020944\n",
      "Iteration 7/10, Loss classification: 0.308996416352352\n",
      "Iteration 8/10, Loss: 3048.6964875896083\n",
      "Iteration 8/10, Loss classification: 0.32826066956479305\n",
      "Iteration 9/10, Loss: 3045.175036798881\n",
      "Iteration 9/10, Loss classification: 0.311010803775823\n",
      "Iteration 10/10, Loss: 3057.8753467177103\n",
      "Iteration 10/10, Loss classification: 0.30132643715145957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples, n_features, n_components = 100, 40, 10\n",
    "X = np.random.randn(n_samples, n_features)  # Input data\n",
    "true_D = np.random.randn(n_features, n_components)  # True dictionary\n",
    "true_alpha = np.random.randn(n_samples, n_components)  # Sparse codes\n",
    "true_theta = np.random.randn(n_components)  # Linear model weights\n",
    "b_true = 0.5  # Bias term\n",
    "\n",
    "\n",
    "# Generate labels based on the linear model\n",
    "y = X @ true_D @ true_theta + b_true + 0.1 * np.random.randn(n_samples)\n",
    "y = np.round(y)  # Binary classification labels (0 or 1)\n",
    "\n",
    "\n",
    "# Initialize the SDL model\n",
    "sdl = SDL_simple(\n",
    "    n_iter=10,\n",
    "    lamnda0=0.01,\n",
    "    lambda1=0.1,\n",
    "    lambda2=0.1,\n",
    "    lr_D=0.01,\n",
    "    lr_theta=0.01,\n",
    "    lr_alpha=0.01,\n",
    "    lambd=0.01\n",
    ")\n",
    "\n",
    "# Fit the model to the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "sdl.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.0\n",
      "Ground truth labels: [ 35.  -5.  16. -36.  -0. -25.  25.   2.   2.   7.]\n",
      "Predicted labels: [ 10. -13. -21. -24. -25. -14. -25.  -3.  29.  -8.]\n",
      "Number of right predictions: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# do the prediction\n",
    "y_pred_train = sdl.predict(X_train)\n",
    "print(\"Train accuracy:\", np.mean(np.round(y_pred_train) == y_train))\n",
    "\n",
    "y_pred_test = sdl.predict(X_test)\n",
    "print(\"Test accuracy:\", np.mean(np.round(y_pred_test) == y_test))\n",
    "print(\"Ground truth labels:\", y_test[:10])\n",
    "print(\"Predicted labels:\", np.round(y_pred_test)[:10])\n",
    "\n",
    "# count the number of right predictions\n",
    "print(\"Number of right predictions:\", np.sum(np.round(y_pred_test) == y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10, Loss: 199507201456356.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermarouani/Desktop/SDL/Supervised_Dictionary_Learning/Models/utils.py:80: RuntimeWarning: invalid value encountered in subtract\n",
      "  alpha_new = self.mu * self.prox_l1(alpha - self.lambd * grad_f, self.lambd * self.lambda_1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2/10, Loss: nan\n",
      "Loss is NaN. Stopping optimization.\n",
      "Progress: 1/9 (11.11%)\n",
      "Lambda0: 0.001, Lambda1: 0.00015, Lambda2: 0.01, Accuracy: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q3/sl_3k64s2ldb0zk8pjw9qplc0000gn/T/ipykernel_48030/3292542789.py\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mlambda2_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_best_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda0_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda2_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/q3/sl_3k64s2ldb0zk8pjw9qplc0000gn/T/ipykernel_48030/3292542789.py\u001b[0m in \u001b[0;36mselect_best_lambda\u001b[0;34m(X, y, lambda0_range, lambda2_range, n_iter)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mlr_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             )\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0msdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/q3/sl_3k64s2ldb0zk8pjw9qplc0000gn/T/ipykernel_48030/2288359708.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0malpha_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             D_opt, theta_opt, b_opt = self.solve_D_theta(alpha_opt,\n\u001b[1;32m     99\u001b[0m                                                             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/q3/sl_3k64s2ldb0zk8pjw9qplc0000gn/T/ipykernel_48030/2288359708.py\u001b[0m in \u001b[0;36msolve_alpha\u001b[0;34m(self, X, y, D, theta, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Solve the problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Random initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0malpha_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/SDL/Supervised_Dictionary_Learning/Models/utils.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, x0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Update rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0malpha_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprox_l1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# Convergence check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def select_best_lambda(X, y, lambda0_range, lambda2_range, n_iter=10):\n",
    "    \"\"\"\n",
    "    Selects the best lambda parameters for the SDL model using grid search with a fixed ratio between lambda1 and lambda0.\n",
    "\n",
    "    Parameters:\n",
    "    - X, y: Dataset for training and evaluation.\n",
    "    - lambda0_range: Range of values to test for lambda0.\n",
    "    - lambda2_range: Range of values to test for lambda2.\n",
    "    - n_iter: Number of iterations for the SDL model.\n",
    "\n",
    "    Returns:\n",
    "    - best_params: Dictionary with the best lambda parameters.\n",
    "    - best_accuracy: Highest accuracy achieved.\n",
    "    \"\"\"\n",
    "    best_accuracy = -float('inf')\n",
    "    best_params = {}\n",
    "\n",
    "    # Total number of combinations to evaluate\n",
    "    total_combinations = len(lambda0_range) * len(lambda2_range)\n",
    "    combination_count = 0\n",
    "\n",
    "    for lambda0 in lambda0_range:\n",
    "        # Calculate lambda1 such that lambda1/lambda0 is approximately 0.15\n",
    "        lambda1 = 0.15 * lambda0\n",
    "\n",
    "        for lambda2 in lambda2_range:\n",
    "            # Increment the combination counter\n",
    "            combination_count += 1\n",
    "\n",
    "            # Initialize and fit the SDL model\n",
    "            sdl = SDL_simple(\n",
    "                n_iter=n_iter,\n",
    "                lamnda0=lambda0,\n",
    "                lambda1=lambda1,\n",
    "                lambda2=lambda2,\n",
    "                lr_D=0.01,\n",
    "                lr_theta=0.01,\n",
    "                lr_alpha=0.01\n",
    "            )\n",
    "            sdl.fit(X, y)\n",
    "\n",
    "            # Evaluate the model\n",
    "            accuracy = sdl.score(X, y)\n",
    "            print(f\"Progress: {combination_count}/{total_combinations} ({(combination_count/total_combinations)*100:.2f}%)\")\n",
    "            print(f\"Lambda0: {lambda0}, Lambda1: {lambda1}, Lambda2: {lambda2}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "            # Update best parameters if the current accuracy is better\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'lambda0': lambda0, 'lambda1': lambda1, 'lambda2': lambda2}\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}, Best Accuracy: {best_accuracy:.2f}\")\n",
    "    return best_params, best_accuracy\n",
    "\n",
    "# Example usage\n",
    "lambda0_range = [0.001, 0.01, 0.1]\n",
    "lambda2_range = [0.01, 0.1, 0.5]\n",
    "\n",
    "best_params, best_accuracy = select_best_lambda(X, y, lambda0_range, lambda2_range)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
